{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b4370c3-bc91-43ec-bdc3-c9ede470fec8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00772607-6241-4827-bae0-54ac5c994bcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = '/home/ec2-user/SageMaker/prediction_July4/Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64378e96-8b5f-4754-b9fe-8d153e0ce4f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_file_paths(data_dir: str) -> list:\n",
    "    \"\"\"Take a directory as input and return a list of paths to all files inside.\"\"\"\n",
    "    file_paths = []\n",
    "    for root_path, _, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('png'):\n",
    "                file_paths.append(os.path.join(root_path, file))\n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c19c6840-831d-44d6-9a2e-f6576842d015",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_images(file_paths, dim=(128, 128), verbose=False):\n",
    "    print(f\"Processing {len(file_paths)} image paths...\") if verbose else None\n",
    "    images = []\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(dim),  # Resize the image\n",
    "        transforms.ToTensor()  # Convert PIL image to PyTorch tensor\n",
    "    ])\n",
    "\n",
    "    for i, file_path in enumerate(file_paths):\n",
    "        f_path = os.path.join(file_path)\n",
    "        if \"checkpoint\" in f_path:\n",
    "            print(f\"[{i+1}] Skipping '{f_path}' (contains 'checkpoint')...\") if verbose else None\n",
    "            continue\n",
    "        \n",
    "        # print(f\"[{i+1}] Loading '{f_path}' . . .\") if verbose else None\n",
    "        image = Image.open(f_path)\n",
    "        \n",
    "        # Convert to RGB if the image has an alpha channel\n",
    "        if image.mode == 'RGBA':\n",
    "            image = image.convert('RGB')\n",
    "        \n",
    "        image = transform(image)\n",
    "        images.append(image)\n",
    "    \n",
    "    # Resize images to a consistent size\n",
    "    resized_images = []\n",
    "    for image in images:\n",
    "        if image.shape != (3, dim[0], dim[1]):\n",
    "            resize_transform = transforms.Resize((dim[1], dim[0]))\n",
    "            image = resize_transform(image)\n",
    "        resized_images.append(image)\n",
    "    \n",
    "    return torch.stack(resized_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d8d7162-a49d-4422-877d-836b50645c8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 501 images in directory.\n"
     ]
    }
   ],
   "source": [
    "file_paths = get_file_paths(output_dir)\n",
    "print(f\"Total {len(file_paths)} images in directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa8f9b78-e619-435e-9013-561f1bdc58c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 501 image paths...\n",
      "[501] Skipping '/home/ec2-user/SageMaker/prediction_July4/Dataset/.ipynb_checkpoints/soloAUV 20220909-022428-001-checkpoint.png' (contains 'checkpoint')...\n"
     ]
    }
   ],
   "source": [
    "# Take a sample of images\n",
    "percent = 100\n",
    "N = int(len(file_paths)*percent)\n",
    "indexes = np.random.randint(low=0, high=len(file_paths), size=N)\n",
    "sample_files = [path for (i, path) in enumerate(file_paths) if i in indexes]\n",
    "X = load_images(sample_files, verbose=True, dim=(128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f7abe67-cab4-429b-9edb-2132fad2c40b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_images(X, n=10, h=28, w=28, latent_vector=False, title=None, plot_type=\"grid\", figsize=(10, 4)):\n",
    "    if plot_type == \"grid\":\n",
    "        num_rows = int(np.ceil(n / 10))\n",
    "        fig, axes = plt.subplots(num_rows, 10, figsize=figsize)\n",
    "        fig.suptitle(title, fontsize=14)\n",
    "        axes = axes.flatten()\n",
    "        for i in range(n):\n",
    "            ax = axes[i]\n",
    "            if latent_vector:\n",
    "                img = X[i].reshape(h, w)\n",
    "            else:\n",
    "                img = np.transpose(X[i], (1, 2, 0))\n",
    "            ax.imshow(img, cmap='gray')\n",
    "            ax.axis('off')\n",
    "    elif plot_type == \"flat\":\n",
    "        fig, axes = plt.subplots(1, n, figsize=figsize)\n",
    "        fig.suptitle(title, fontsize=14)\n",
    "        for i in range(n):\n",
    "            ax = axes[i]\n",
    "            if latent_vector:\n",
    "                img = X[i].reshape(h, w)\n",
    "            else:\n",
    "                img = np.transpose(X[i], (1, 2, 0))\n",
    "            ax.imshow(img, cmap='gray')\n",
    "            ax.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d073f0-3e39-43f1-afa2-7012e516e84b",
   "metadata": {},
   "source": [
    "# Building Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27314937-a83f-4f38-9694-fbdbbe4ade1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0882c7f5-25ee-4cfa-81d0-936fd74373df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(8, 8, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # Code (latent vector)\n",
    "        self.code = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8, 8, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.ConvTranspose2d(8, 8, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.ConvTranspose2d(8, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(16, 3, kernel_size=3, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        code = self.code(encoded)\n",
    "        decoded = self.decoder(code)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a783273d-3724-4975-bbdb-f37a3774c612",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Create data loaders\n",
    "loader = DataLoader(X.to(device), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Define the number of epochs\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131fc636-dd38-410b-9000-283c5c1ad770",
   "metadata": {},
   "source": [
    "# PredictionLoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98e1917f-b368-4c0d-9ff4-3c7a37493d97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 512)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Too many dimensions: 3 > 2.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_15233/998912108.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     92\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     93\u001B[0m     \u001B[0;31m# Convert the numpy array to an image using PIL\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 94\u001B[0;31m     \u001B[0mpil_image\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mImage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfromarray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0;36m255\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0muint8\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'L'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     95\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     96\u001B[0m     \u001B[0;31m# Save the image\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/PIL/Image.py\u001B[0m in \u001B[0;36mfromarray\u001B[0;34m(obj, mode)\u001B[0m\n\u001B[1;32m   3101\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mndim\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0mndmax\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3102\u001B[0m         \u001B[0mmsg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34mf\"Too many dimensions: {ndim} > {ndmax}.\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3103\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmsg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3104\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3105\u001B[0m     \u001B[0msize\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m1\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mndim\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Too many dimensions: 3 > 2."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have defined Autoencoder class as mentioned in your last message\n",
    "\n",
    "# Set device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming you have already defined train_loader and test_loader\n",
    "\n",
    "# Load the model checkpoint and state dictionary\n",
    "checkpoint = torch.load('/home/ec2-user/SageMaker/autoencoder_weights.pt', map_location=device)\n",
    "\n",
    "autoencoder = Autoencoder().to(device)\n",
    "\n",
    "# Load the encoder's state dictionary\n",
    "encoder_state_dict = {\n",
    "    k.replace('encoder.', ''): v for k, v in checkpoint.items() if k.startswith('encoder.')\n",
    "}\n",
    "autoencoder.encoder.load_state_dict(encoder_state_dict)\n",
    "\n",
    "# Load the decoder's state dictionary\n",
    "decoder_state_dict = {\n",
    "    k.replace('decoder.', ''): v for k, v in checkpoint.items() if k.startswith('decoder.')\n",
    "}\n",
    "autoencoder.decoder.load_state_dict(decoder_state_dict)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "autoencoder.eval()\n",
    "\n",
    "\n",
    "# Initialize lists to store latent vectors and targets\n",
    "latent_vectors = []\n",
    "targets = []\n",
    "\n",
    "# Generate latent vectors using the data from the loader\n",
    "with torch.no_grad():\n",
    "    for batch_data in loader:\n",
    "        # Move data to CUDA device\n",
    "        batch_data = batch_data.to(device)\n",
    "        \n",
    "        # Forward pass to get the latent vectors\n",
    "        latent_vector = autoencoder.code(autoencoder.encoder(batch_data))\n",
    "        \n",
    "        # Move the latent vector and target back to the CPU\n",
    "        latent_vectors.extend(latent_vector.cpu().numpy())\n",
    "        targets.extend(batch_data.cpu().numpy())\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "latent_vectors = np.array(latent_vectors)\n",
    "\n",
    "# Flatten the latent_vectors array\n",
    "latent_vectors = latent_vectors.reshape(latent_vectors.shape[0], -1)\n",
    "\n",
    "print(latent_vectors.shape)\n",
    "gmm.fit_predict(latent_vectors)\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Apply Gaussian Mixture Model for clustering\n",
    "k_value = 3\n",
    "gmm = GaussianMixture(n_components=k_value)\n",
    "cluster_labels = gmm.fit_predict(latent_vectors)\n",
    "\n",
    "import os\n",
    "\n",
    "output_dir = \"./cluster analysis\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create subfolders for each cluster\n",
    "for i in range(k_value):\n",
    "    cluster_dir = os.path.join(output_dir, f\"cluster_{i}\")\n",
    "    os.makedirs(cluster_dir, exist_ok=True)\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Loop through the images and save them to the corresponding cluster folders\n",
    "for idx, (image, cluster_label) in enumerate(zip(targets, cluster_labels)):\n",
    "    cluster_dir = os.path.join(output_dir, f\"cluster_{cluster_label}\")\n",
    "    image_filename = f\"image_{idx}.png\"\n",
    "    image_path = os.path.join(cluster_dir, image_filename)\n",
    "\n",
    "    # Convert the numpy array to an image using PIL\n",
    "    pil_image = Image.fromarray((image * 255).astype(np.uint8), mode='L')\n",
    "    \n",
    "    # Save the image\n",
    "    pil_image.save(image_path)\n",
    "\n",
    "    \n",
    "# Continue with the code to create the t-SNE plot using the `clusters` dictionary\n",
    "\n",
    "# Concatenate the clusters into a single array\n",
    "concatenated_clusters = np.concatenate(list(clusters.values()))\n",
    "\n",
    "# Create a DataFrame for the concatenated clusters\n",
    "df_concatenated = pd.DataFrame(concatenated_clusters)\n",
    "\n",
    "# Add a column for cluster labels\n",
    "df_concatenated['clusterid'] = np.concatenate([np.full(len(cluster), cid) for cid, cluster in clusters.items()])\n",
    "\n",
    "# Perform t-SNE on the concatenated data\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_representation = tsne.fit_transform(df_concatenated.drop('clusterid', axis=1))\n",
    "\n",
    "# Create a scatter plot of the t-SNE representation with cluster labels\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=tsne_representation[:, 0], y=tsne_representation[:, 1], hue=df_concatenated['clusterid'], palette='Set1', legend='full')\n",
    "plt.title('t-SNE Plot of All Clusters')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56d751a2-6085-4a80-bce3-e487b4967bbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['encoder.0.weight', 'encoder.0.bias', 'encoder.3.weight', 'encoder.3.bias', 'encoder.6.weight', 'encoder.6.bias', 'decoder.0.weight', 'decoder.0.bias', 'decoder.3.weight', 'decoder.3.bias', 'decoder.6.weight', 'decoder.6.bias', 'decoder.9.weight', 'decoder.9.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(checkpoint.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562b3484-324a-419b-8e54-d1256ac9102d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the model checkpoint and state dictionary\n",
    "checkpoint = torch.load('/home/ec2-user/SageMaker/Zooplankon_latent_AE.pt')\n",
    "autoencoder = Autoencoder().to(device)\n",
    "autoencoder.load_state_dict(checkpoint['model_state_dict'])\n",
    "autoencoder.eval()\n",
    "\n",
    "# Initialize lists to store latent vectors and targets\n",
    "latent_vectors = []\n",
    "targets = []\n",
    "\n",
    "# Generate latent vectors using the data from the loader\n",
    "with torch.no_grad():\n",
    "    for batch_data, _ in loader:\n",
    "        # Resize the target tensors to match the output size\n",
    "        target = torch.nn.functional.interpolate(batch_data, size=(128, 128), mode='bilinear', align_corners=False)\n",
    "            \n",
    "        # Move data to CUDA device\n",
    "        batch_data = batch_data.to(device)\n",
    "        target = target.to(device)\n",
    "            \n",
    "        # Forward pass to get the latent vectors\n",
    "        latent_vector = autoencoder.encode(batch_data)\n",
    "        \n",
    "        # Move the latent vector and target back to the CPU\n",
    "        latent_vectors.extend(latent_vector.cpu().numpy())\n",
    "        targets.extend(target.cpu().numpy())\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "latent_vectors = np.array(latent_vectors)\n",
    "targets = np.array(targets)\n",
    "\n",
    "# Apply Gaussian Mixture Model for clustering\n",
    "k_value = 2\n",
    "gmm = GaussianMixture(n_components=k_value)\n",
    "cluster_labels = gmm.fit_predict(latent_vectors)\n",
    "\n",
    "# Visualization of the clusters\n",
    "plt.scatter(latent_vectors[cluster_labels == 0, 0], latent_vectors[cluster_labels == 0, 1], c='red', label='Cluster 1')\n",
    "plt.scatter(latent_vectors[cluster_labels == 1, 0], latent_vectors[cluster_labels == 1, 1], c='blue', label='Cluster 2')\n",
    "plt.title('Latent Space Clustering')\n",
    "plt.xlabel('Latent Dimension 1')\n",
    "plt.ylabel('Latent Dimension 2')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33487387-c44e-4e31-87aa-1f03b2b38e6c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# EM Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da898435-9e94-4089-b68b-84d611f9c768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# Define the number of clusters and random state\n",
    "k = 7\n",
    "random_state = np.random.randint(0, 500)\n",
    "\n",
    "# Fit Gaussian Mixture Model\n",
    "gmm = GaussianMixture(n_components=k, random_state=random_state)\n",
    "gmm.fit(latent_vector.cpu())\n",
    "cluster_id = gmm.predict(latent_vector.cpu())\n",
    "\n",
    "# Create DataFrame with cluster labels\n",
    "df = pd.DataFrame(X_test.cpu().reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2]*X_test.shape[3]))\n",
    "df[\"clusterid\"] = cluster_id\n",
    "\n",
    "# Store clusters in a dictionary\n",
    "clusters = dict()\n",
    "for cid in df.clusterid.unique():\n",
    "    clusters[cid] = df[df.clusterid == cid].drop(\"clusterid\", axis=\"columns\").to_numpy()\n",
    "\n",
    "# Function to visualize random samples\n",
    "def show_random_samples(X, n=12, h=400, w=400, latent_vector=False, title=\"\", figsize=(16, 16), plot_type=\"grid\"):\n",
    "    # Reshape if needed\n",
    "    if X.ndim == 2 and latent_vector:\n",
    "        X = X.reshape(X.shape[0], 3, h, w)\n",
    "    if X.ndim == 2:\n",
    "        X = X.reshape(X.shape[0], 3, h, w)\n",
    "    \n",
    "    # Take random sample\n",
    "    idxs = np.random.randint(len(X), size=n)\n",
    "    \n",
    "    # Create a list to store images from each cluster\n",
    "    cluster_images = [[] for _ in range(n)]\n",
    "    \n",
    "    # Collect images from each cluster\n",
    "    for i, idx in enumerate(idxs):\n",
    "        cluster_images[i % n].append(X[idx])\n",
    "    \n",
    "    # Calculate optimal figsize for horizontal display\n",
    "    image_height = cluster_images[0][0].shape[1]\n",
    "    image_width = cluster_images[0][0].shape[2]\n",
    "    figsize = (figsize[0], (figsize[0] / n) * (image_height / image_width))\n",
    "    \n",
    "    # Plot images horizontally for each cluster\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=n, figsize=figsize)\n",
    "    for i, images in enumerate(cluster_images):\n",
    "        combined_image = np.concatenate(images, axis=2)\n",
    "        ax[i].imshow(combined_image.transpose(1, 2, 0))\n",
    "        ax[i].axis('off')\n",
    "        ax[i].set_aspect('auto')\n",
    "    \n",
    "    # Show plot\n",
    "    plt.suptitle(title, fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize clusters\n",
    "for cid in sorted(clusters.keys()):\n",
    "    show_random_samples(clusters[cid], h=128, w=128, n=8, title=f\"cluster {cid}\", plot_type=\"grid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9955835-c759-47df-8d5c-c09c347d73b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have the `clusters` dictionary containing the cluster data\n",
    "\n",
    "# Concatenate the clusters into a single array\n",
    "concatenated_clusters = np.concatenate(list(clusters.values()))\n",
    "\n",
    "# Create a DataFrame for the concatenated clusters\n",
    "df_concatenated = pd.DataFrame(concatenated_clusters)\n",
    "\n",
    "# Add a column for cluster labels\n",
    "df_concatenated['clusterid'] = np.concatenate([np.full(len(cluster), cid) for cid, cluster in clusters.items()])\n",
    "\n",
    "# Perform t-SNE on the concatenated data\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_representation = tsne.fit_transform(df_concatenated.drop('clusterid', axis=1))\n",
    "\n",
    "# Create a scatter plot of the t-SNE representation with cluster labels\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=tsne_representation[:, 0], y=tsne_representation[:, 1], hue=df_concatenated['clusterid'], palette='Set1', legend='full')\n",
    "plt.title('t-SNE Plot of All Clusters')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74817c30-4f98-4c1b-b644-8fdd39a0ff62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
